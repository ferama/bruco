[{"uri":"https://ferama.github.io/bruco/basic/","title":"Getting started","tags":[],"description":"","content":"Introduction Discover what bruco can do\nLet\u0026rsquo;s start\n"},{"uri":"https://ferama.github.io/bruco/sources/http/","title":"Http","tags":[],"description":"","content":"The http source is activated using the http kind\n   yaml path description     ignoreProcessorResponse If true the http request returns quickly. Do not wait for a processor response   port the port the http server listens too (do not change this if you are using bruco with k8s)    Example:\nsource: kind: http ignoreProcessorResponse: false # port: 8090 "},{"uri":"https://ferama.github.io/bruco/sinks/kafka/","title":"Kafka","tags":[],"description":"","content":"The kafka sink is activated using the kafka kind\nExample:\n# OPTIONAL: you can have a source and a processor without a sink sink: kind: kafka brokers: - localhost:9092 topic: test-out # OPTIONAL: target partition partition: 42 # OPTIONAL: default hash if partition is not defined. values: manual, hash, random partitioner: hash "},{"uri":"https://ferama.github.io/bruco/sources/kafka/","title":"Kafka","tags":[],"description":"","content":"Bruco uses Sarama (https://github.com/Shopify/sarama) as kafka library.\nThe kafka source is activated using the kafka kind\n   yaml path description     brokers a list of kafka brokers to connect to   topics a list of topics to subscribe too   offset the initial offset where the kafka consumer will start to consume   consumerGroup the kafka consumer group   balanceStrategy the kafka consumer balance startegy   fireAndForget if true, the first available worker will process a message, regardless of partition message order   rebalanceTimeout kafka rebalanceTimeout   channelBufferSize the size of consumer buffer   fetchDefaultBytes the size in bytes to fetch from the topic each time    Example:\nsource: kind: kafka brokers: - localhost:9092 topics: - test1 - test2 # OPTIONAL: default latest. values: latest, earliest offset: latest consumerGroup: my-consumer-group # OPTIONAL: default range. values: range, sticky, roundrobin balanceStrategy: range # NOTE: the async version (fireAndForget=true) will not guarantee # messages handling order between same partition fireAndForget: false # OPTIONAL: default 60 # Increase this one if you have slow consumers to prevent # rebalance loop rebalanceTimeout: 120 # OPTIONAL: default to 256. Put a low vaclue here in case of slow consumers # to prevent rebalancing loop. It can be as low as 0 channelBufferSize: 256 # OPTIONAL: default 1024 * 1024. Again for slow consumers you could keep this low fetchDefaultBytes: 8 Understand the balanceStrategy param The balanceStrategy param, let\u0026rsquo;s you config the partition assignment strategy per consumer. There are 3 available values:\n Range (default) Stick Round Robin  The range partition strategy, distributes partitions to consumers as ranges. Example: suppose you have 6 partitions and two consumers. The assignement strategy will be like:\n c1: [p0, p1, p2] c2: [p3, p4, p5] The sticky partition strategy, will assign partitions to consumer trying to keep previous assignment while at the sime time obtaining a balanced partition distribution. Example: you have 6 partition and two consumer with an assignment like:\n c1: [p0, p2, p4] c2: [p1, p3, p5] then a new consumer joins the consumer group. You could obtain a reassigment like:\n c1: [p0, p2] c2: [p1, p3] c3: [p4, p5] The roundrobin partition strategy, uses a round robin parition distribution between consumers. Example: with 6 paritions and two consumers, you will get:\n c1: [p0, p2, p4] c2: [p1, p3, p5] "},{"uri":"https://ferama.github.io/bruco/sinks/nats/","title":"NATS","tags":[],"description":"","content":"The nats sink is activated using the nats kind\nExample:\n# OPTIONAL: you can have a source and a processor without a sink sink: kind: nats serverUrl: localhost:4222 subject: out.sub "},{"uri":"https://ferama.github.io/bruco/sources/nats/","title":"NATS","tags":[],"description":"","content":"The NATS source is activated using the nats kind\nExample:\nsource: kind: nats serverUrl: localhost:4222 queueGroup: test subject: in.sub "},{"uri":"https://ferama.github.io/bruco/sources/","title":"Sources","tags":[],"description":"","content":"Sources Actually bruco supports the following event sources:\n HTTP Apache Kafka NATS  "},{"uri":"https://ferama.github.io/bruco/processor/","title":"Processor","tags":[],"description":"","content":"Processor TODO\n"},{"uri":"https://ferama.github.io/bruco/sinks/","title":"Sinks","tags":[],"description":"","content":"Sinks Actually bruco supports the following output sinks:\n Apache Kafka NATS  "},{"uri":"https://ferama.github.io/bruco/","title":"Bruco","tags":[],"description":"","content":"Bruco Bruco is a tool meant to build streaming pipelines steps easily. It is kubernetes native citizen. Each step can be indeed, defined using a Kubernetes custom resource. You don\u0026rsquo;t even need to manually build a docker image.\nThe pipeline is event-driven and implements the paradigm:\ngraph LR; A[Source] -- B(Processor) -- C[Sink]  The processor is meant for stream transformation between the source and the sink. Bruco supports writing processor logic using the python scripting language.\nSources Actually bruco supports the following event sources:\n HTTP Apache Kafka NATS  Sinks Follows the actually supported sinks list\n Apache Kafka NATS  Follow the Getting Started guide for a beginner tutorial.\n "},{"uri":"https://ferama.github.io/bruco/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://ferama.github.io/bruco/basic/getting-started/","title":"Getting started on k8s","tags":[],"description":"","content":"This guide will introduce you to the bruco concept e will help to get the stuff up and running quickly.\nThis tutorial make some assumptions:\n You have a kubernetes environment up and running You have correctly configured the kubectl cli tool to interact with the env above  Bruco is heavily integrated with Kubernetes. To get start to experiment with bruco function deployment you need to setup some stuff on kubernetes first.\nBruco defines a custom resource for its functions. The resource is called guess that, bruco ðŸ™‚\nThis is a sample resource instance that you will able to create:\napiVersion: bruco.ferama.github.com/v1alpha1 kind: Bruco metadata: name: example-bruco spec: replicas: 1 functionURL: https://github.com/ferama/bruco/raw/main/hack/examples/zipped/sentiment.zip but before that, you need to create the custom resource definition on k8s and to deploy the controller supporting the custom resource.\nFollow this steps to do that.\nk8s controller deployment # create a new k8s namespace for bruco $ kubectl create ns bruco # create the custom resource $ kubectl -n bruco apply -f https://raw.githubusercontent.com/ferama/bruco/main/hack/k8s/resources/crd-bruco.yaml # deploy the bruco controller $ kubectl -n bruco apply -f https://raw.githubusercontent.com/ferama/bruco/main/hack/k8s/resources/controller.yaml The result should be something like this, that means that the bruco controller is up and running:\n$ kubectl -n bruco get pods NAME READY STATUS RESTARTS AGE bruco-controller-5fd955d49-7p6xt 1/1 Running 0 37s demo function deployment Now you are ready to deploy your first bruco function. Create a file named example-bruco.yaml and copy and paste the example bruco function definition:\napiVersion: bruco.ferama.github.com/v1alpha1 kind: Bruco metadata: name: example-bruco spec: replicas: 1 functionURL: https://github.com/ferama/bruco/raw/main/hack/examples/zipped/sentiment.zip Create the kubernetes resource using:\n$ kubectl -n bruco apply -f example-bruco.yaml What is happening here, is that bruco will load the package at https://github.com/ferama/bruco/raw/main/hack/examples/zipped/sentiment.zip and starts a deployment with one replicas that will run the sentiment function. The zip file contains all the required config and logic to run the function. In this example the zip file contains:\n A bruco config.yaml file An handler.py with the function logic A requirements.txt file that declares the funcion dependencies  The config.yaml file contains the bruco function config about source, sink and processor. For this example it is very simple:\nprocessor: handlerPath: . moduleName: handler workers: 2 source: kind: http The handler is a very simple python function:\nfrom textblob import TextBlob def handle_event(context, data): blob = TextBlob(data.decode()) return { \u0026#34;sentiment\u0026#34;: blob.sentiment.polarity, \u0026#34;subjectivity\u0026#34;: blob.sentiment.subjectivity } The handler function requires the textblob library. The dependency is defined in the requirements.txt file\ntextblob Now you are ready to test out your first bruco function. Let\u0026rsquo;s forward the http source port:\n# forwards the http source port $ kubectl -n bruco port-forward svc/example-bruco 8080 # generate an event using the http source $ curl -X POST -d \u0026#34;bruco is great\u0026#34; http://localhost:8080 {\u0026#34;sentiment\u0026#34;: 0.8, \u0026#34;subjectivity\u0026#34;: 0.75} "},{"uri":"https://ferama.github.io/bruco/tags/","title":"Tags","tags":[],"description":"","content":""}]