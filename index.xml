<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Bruco on Bruco üêõ</title><link>https://ferama.github.io/bruco/</link><description>Recent content in Bruco on Bruco üêõ</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="https://ferama.github.io/bruco/index.xml" rel="self" type="application/rss+xml"/><item><title>Http</title><link>https://ferama.github.io/bruco/sources/http/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ferama.github.io/bruco/sources/http/</guid><description>The http source is activated using the http kind
yaml path description ignoreProcessorResponse If true the http request returns quickly. Do not wait for a processor response port the port the http server listens too (do not change this if you are using bruco with k8s) Example:
source: kind: http ignoreProcessorResponse: false # port: 8090</description></item><item><title>Kafka</title><link>https://ferama.github.io/bruco/sinks/kafka/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ferama.github.io/bruco/sinks/kafka/</guid><description>The kafka sink is activated using the kafka kind
Example:
# OPTIONAL: you can have a source and a processor without a sink sink: kind: kafka brokers: - localhost:9092 topic: test-out # OPTIONAL: target partition partition: 42 # OPTIONAL: default hash if partition is not defined. values: manual, hash, random partitioner: hash</description></item><item><title>Kafka</title><link>https://ferama.github.io/bruco/sources/kafka/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ferama.github.io/bruco/sources/kafka/</guid><description>Bruco uses Sarama (https://github.com/Shopify/sarama) as kafka library.
The kafka source is activated using the kafka kind
yaml path description brokers a list of kafka brokers to connect to topics a list of topics to subscribe too offset the initial offset where the kafka consumer will start to consume consumerGroup the kafka consumer group balanceStrategy the kafka consumer balance startegy fireAndForget if true, the first available worker will process a message, regardless of partition message order rebalanceTimeout kafka rebalanceTimeout channelBufferSize the size of consumer buffer fetchDefaultBytes the size in bytes to fetch from the topic each time Example:</description></item><item><title>NATS</title><link>https://ferama.github.io/bruco/sinks/nats/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ferama.github.io/bruco/sinks/nats/</guid><description>The nats sink is activated using the nats kind
Example:
# OPTIONAL: you can have a source and a processor without a sink sink: kind: nats serverUrl: localhost:4222 subject: out.sub</description></item><item><title>NATS</title><link>https://ferama.github.io/bruco/sources/nats/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ferama.github.io/bruco/sources/nats/</guid><description>The NATS source is activated using the nats kind
Example:
source: kind: nats serverUrl: localhost:4222 queueGroup: test subject: in.sub</description></item><item><title>Bruco on kubernetes</title><link>https://ferama.github.io/bruco/kubernetes/kubernetes/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ferama.github.io/bruco/kubernetes/kubernetes/</guid><description>Bruco on kubernetes is supported by a custom resource and controller.
This is a resource instance definition example:
apiVersion: bruco.ferama.github.io/v1alpha1 kind: Bruco metadata: name: example-bruco-s3 spec: replicas: 1 env: - name: AWS_ACCESS_KEY_ID value: bruco - name: AWS_SECRET_ACCESS_KEY value: bruco123 functionURL: s3://bruco-minio.bruco:9000/brucos/image-classifier.zip stream: processor: workers: 2 source: kind: http The resource supports the following fields:
yaml path description replicas the bruco pod replicas that should be instantiated image if you wish to set a custom docker image imagePullPolicy standard kubernetes imagePullPolicy imagePullSecrets standard kubernetes imagePullSecrets resources standard kubernetes resources limit and requests env an array of objects of kind name, value that defines env vars exposed to the pods functionURL a function package url.</description></item><item><title>Getting started on k8s</title><link>https://ferama.github.io/bruco/basic/getting-started/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ferama.github.io/bruco/basic/getting-started/</guid><description>This guide will introduce you to the bruco concept and will help to get the stuff up and running quickly.
This tutorial make some assumptions:
You have a kubernetes environment up and running You have correctly configured the kubectl cli tool to interact with the env above Bruco is heavily integrated with Kubernetes. To get start to experiment with bruco function deployment you need to setup some stuff on kubernetes first.</description></item><item><title>Processor</title><link>https://ferama.github.io/bruco/processor/processor/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ferama.github.io/bruco/processor/processor/</guid><description>Bruco processor is a binary executable that handle all the
graph LR; A[Source] -- B(Processor) -- C[Sink] flow. In details it does the following things:
Loads and parses a config.yaml file containing the stream definition Starts the Source and Sink accordingly Starts a pool of workers (python processes) as per configuration Handles the stream The processor section of the config file supports the following attributes:
yaml path description handlerPath the path to the python file where the handle is defined (by default the current working dir) moduleName the python module containing the handle_event function (by default handler) workers the number of worker to start up env an array of objects of type name, value defining the env vars to expose to the workers processes This is a full config example where we define processor, source and sink conf</description></item></channel></rss>