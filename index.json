[{"uri":"https://ferama.github.io/bruco/basic/","title":"Getting started","tags":[],"description":"","content":"Introduction Discover what bruco can do\nLet\u0026rsquo;s start\n"},{"uri":"https://ferama.github.io/bruco/sources/http/","title":"Http","tags":[],"description":"","content":"The http source is activated using the http kind\n   yaml path description     ignoreProcessorResponse If true the http request returns quickly. Do not wait for a processor response   port the port the http server listens too (do not change this if you are using bruco with k8s)    Example:\nsource: kind: http ignoreProcessorResponse: false # port: 8090 "},{"uri":"https://ferama.github.io/bruco/sinks/kafka/","title":"Kafka","tags":[],"description":"","content":"The kafka sink is activated using the kafka kind\nExample:\n# OPTIONAL: you can have a source and a processor without a sink sink: kind: kafka brokers: - localhost:9092 topic: test-out # OPTIONAL: target partition partition: 42 # OPTIONAL: default hash if partition is not defined. values: manual, hash, random partitioner: hash "},{"uri":"https://ferama.github.io/bruco/sources/kafka/","title":"Kafka","tags":[],"description":"","content":"Bruco uses Sarama (https://github.com/Shopify/sarama) as kafka library.\nThe kafka source is activated using the kafka kind\n   yaml path description     brokers a list of kafka brokers to connect to   topics a list of topics to subscribe too   offset the initial offset where the kafka consumer will start to consume   consumerGroup the kafka consumer group   balanceStrategy the kafka consumer balance startegy   fireAndForget if true, the first available worker will process a message, regardless of partition message order   rebalanceTimeout kafka rebalanceTimeout   channelBufferSize the size of consumer buffer   fetchDefaultBytes the size in bytes to fetch from the topic each time    Example:\nsource: kind: kafka brokers: - localhost:9092 topics: - test1 - test2 # OPTIONAL: default latest. values: latest, earliest offset: latest consumerGroup: my-consumer-group # OPTIONAL: default range. values: range, sticky, roundrobin balanceStrategy: range # NOTE: the async version (fireAndForget=true) will not guarantee # messages handling order between same partition fireAndForget: false # OPTIONAL: default 60 # Increase this one if you have slow consumers to prevent # rebalance loop rebalanceTimeout: 120 # OPTIONAL: default to 256. Put a low vaclue here in case of slow consumers # to prevent rebalancing loop. It can be as low as 0 channelBufferSize: 256 # OPTIONAL: default 1024 * 1024. Again for slow consumers you could keep this low fetchDefaultBytes: 8 Understand the balanceStrategy param The balanceStrategy param, let\u0026rsquo;s you config the partition assignment strategy per consumer. There are 3 available values:\n Range (default) Stick Round Robin  The range partition strategy, distributes partitions to consumers as ranges. Example: suppose you have 6 partitions and two consumers. The assignement strategy will be like:\n c1: [p0, p1, p2] c2: [p3, p4, p5] The sticky partition strategy, will assign partitions to consumer trying to keep previous assignment while at the sime time obtaining a balanced partition distribution. Example: you have 6 partition and two consumer with an assignment like:\n c1: [p0, p2, p4] c2: [p1, p3, p5] then a new consumer joins the consumer group. You could obtain a reassigment like:\n c1: [p0, p2] c2: [p1, p3] c3: [p4, p5] The roundrobin partition strategy, uses a round robin parition distribution between consumers. Example: with 6 paritions and two consumers, you will get:\n c1: [p0, p2, p4] c2: [p1, p3, p5] "},{"uri":"https://ferama.github.io/bruco/sinks/nats/","title":"NATS","tags":[],"description":"","content":"The nats sink is activated using the nats kind\nExample:\n# OPTIONAL: you can have a source and a processor without a sink sink: kind: nats serverUrl: localhost:4222 subject: out.sub "},{"uri":"https://ferama.github.io/bruco/sources/nats/","title":"NATS","tags":[],"description":"","content":"The NATS source is activated using the nats kind\nExample:\nsource: kind: nats serverUrl: localhost:4222 queueGroup: test subject: in.sub "},{"uri":"https://ferama.github.io/bruco/kubernetes/","title":"Kubernetes","tags":[],"description":"","content":"Kubernetes Brucos live better in kubernetes ðŸ™‚\nLet\u0026rsquo;s start here for more details\n"},{"uri":"https://ferama.github.io/bruco/sources/","title":"Sources","tags":[],"description":"","content":"Sources Actually bruco supports the following event sources:\n HTTP Apache Kafka NATS  "},{"uri":"https://ferama.github.io/bruco/processor/","title":"Processor","tags":[],"description":"","content":"Processor The processor supports the business logic. Python is the lang of choice to implement the logic.\nExplore processor\n"},{"uri":"https://ferama.github.io/bruco/sinks/","title":"Sinks","tags":[],"description":"","content":"Sinks Actually bruco supports the following output sinks:\n Apache Kafka NATS  "},{"uri":"https://ferama.github.io/bruco/","title":"Bruco","tags":[],"description":"","content":"Bruco Bruco is a tool meant to build streaming pipelines steps easily. It is kubernetes native citizen. Each step can be indeed, defined using a Kubernetes custom resource. You don\u0026rsquo;t even need to manually build a docker image.\nThe pipeline is event-driven and implements the paradigm:\ngraph LR; A[Source] -- B(Processor) -- C[Sink]  The processor is meant for stream transformation between the source and the sink. Bruco supports writing processor logic using the python scripting language.\nSources Actually bruco supports the following event sources:\n HTTP Apache Kafka NATS  Sinks Follows the actually supported sinks list\n Apache Kafka NATS  Follow the Getting Started guide for a beginner tutorial.\n "},{"uri":"https://ferama.github.io/bruco/kubernetes/kubernetes/","title":"Bruco on kubernetes","tags":[],"description":"","content":"Bruco on kubernetes is supported by a custom resource and controller.\nThis is a resource instance definition example:\napiVersion: bruco.ferama.github.io/v1alpha1 kind: Bruco metadata: name: example-bruco-s3 spec: replicas: 1 env: - name: AWS_ACCESS_KEY_ID value: bruco - name: AWS_SECRET_ACCESS_KEY value: bruco123 functionURL: s3://bruco-minio.bruco:9000/brucos/image-classifier.zip stream: processor: workers: 2 source: kind: http The resource supports the following fields:\n   yaml path description     replicas the bruco pod replicas that should be instantiated   image if you wish to set a custom docker image   imagePullPolicy standard kubernetes imagePullPolicy   imagePullSecrets standard kubernetes imagePullSecrets   resources standard kubernetes resources limit and requests   env an array of objects of kind name, value that defines env vars exposed to the pods   functionURL a function package url. This where the handler code and requirements resides   stream is the bruco config subsection   stream.processor refer to the processor docs for details   stream.source refer to the source docs for details   stream.sink refer to the sink docs for details    functionURL in depth Bruco actually is able to load functions from three sources:\n local path http endpoint s3 endpoint  local path The local path supports loading, assumes that the function zip archive resides into the local filesystem. This is usefull if you want/need to build a custom image.\nhttp endpoint The http endpoint will let you load a function from an http endpoint. Example:\nfunctionURL: https://github.com/ferama/bruco/raw/main/examples/zipped/sentiment.zip  Actually the endpoint needs to be public, bruco doesn\u0026rsquo;t not support any kind of auth mechanism. It can be a service inside your k8s cluster\n s3 endpoint The s3 endpoint will let you load a function from minio/s3. It requires the definition of two env vars:\n AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY  Example:\nenv: - name: AWS_ACCESS_KEY_ID value: bruco - name: AWS_SECRET_ACCESS_KEY value: bruco123 functionURL: s3://bruco-minio.bruco:9000/brucos/image-classifier.zip "},{"uri":"https://ferama.github.io/bruco/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://ferama.github.io/bruco/basic/getting-started/","title":"Getting started on k8s","tags":[],"description":"","content":"This guide will introduce you to the bruco concept and will help to get the stuff up and running quickly.\nThis tutorial make some assumptions:\n You have a kubernetes environment up and running You have correctly configured the kubectl cli tool to interact with the env above  Bruco is heavily integrated with Kubernetes. To get start to experiment with bruco function deployment you need to setup some stuff on kubernetes first.\nBruco defines a custom resource for its functions. The resource is called guess that, bruco ðŸ™‚\nThis is a sample resource instance that you will able to create:\napiVersion: bruco.ferama.github.io/v1alpha1 kind: Bruco metadata: name: example-bruco spec: replicas: 1 functionURL: https://github.com/ferama/bruco/raw/main/examples/zipped/sentiment.zip stream: processor: workers: 2 source: kind: http ignoreProcessorResponse: false but before that, you need to create the custom resource definition on k8s and to deploy the controller supporting the custom resource.\nFollow this steps to do that.\nk8s controller deployment # create a new k8s namespace for bruco $ kubectl create ns bruco # create the custom resource $ kubectl -n bruco apply -f https://raw.githubusercontent.com/ferama/bruco/main/hack/k8s/resources/crd-bruco.yaml # deploy the bruco controller $ kubectl -n bruco apply -f https://raw.githubusercontent.com/ferama/bruco/main/hack/k8s/resources/controller.yaml The result should be something like this, that means that the bruco controller is up and running:\n$ kubectl -n bruco get pods NAME READY STATUS RESTARTS AGE bruco-controller-5fd955d49-7p6xt 1/1 Running 0 37s demo function deployment Now you are ready to deploy your first bruco function. Create a file named example-bruco.yaml and copy and paste the example bruco function definition:\napiVersion: bruco.ferama.github.io/v1alpha1 kind: Bruco metadata: name: example-bruco spec: replicas: 1 functionURL: https://github.com/ferama/bruco/raw/main/examples/zipped/sentiment.zip stream: processor: workers: 2 source: kind: http ignoreProcessorResponse: false Create the kubernetes resource using:\n$ kubectl -n bruco apply -f example-bruco.yaml What is happening here, is that bruco will load the package at https://github.com/ferama/bruco/raw/main/hack/examples/zipped/sentiment.zip and starts a deployment with one replicas that will run the sentiment function. The zip file contains all the required config and logic to run the function. In this example the zip file contains:\n An handler.py with the function logic A requirements.txt file that declares the funcion dependencies  The handler is a very simple python function:\nfrom textblob import TextBlob def handle_event(context, data): blob = TextBlob(data.decode()) return { \u0026#34;sentiment\u0026#34;: blob.sentiment.polarity, \u0026#34;subjectivity\u0026#34;: blob.sentiment.subjectivity } The handler function requires the textblob library. The dependency is defined in the requirements.txt file\ntextblob Now you are ready to test out your first bruco function. Let\u0026rsquo;s forward the http source port:\n# forwards the http source port $ kubectl -n bruco port-forward svc/example-bruco 8080 # generate an event using the http source $ curl -X POST -d \u0026#34;bruco is great\u0026#34; http://localhost:8080 {\u0026#34;sentiment\u0026#34;: 0.8, \u0026#34;subjectivity\u0026#34;: 0.75}  For more details about bruco on k8s go here.\n "},{"uri":"https://ferama.github.io/bruco/processor/processor/","title":"Processor","tags":[],"description":"","content":"Bruco processor is a binary executable that handle all the\ngraph LR; A[Source] -- B(Processor) -- C[Sink]  flow. In details it does the following things:\n Loads and parses a config.yaml file containing the stream definition Starts the Source and Sink accordingly Starts a pool of workers (python processes) as per configuration Handles the stream  The processor section of the config file supports the following attributes:\n   yaml path description     handlerPath the path to the python file where the handle is defined (by default the current working dir)   moduleName the python module containing the handle_event function (by default handler)   workers the number of worker to start up   env an array of objects of type name, value defining the env vars to expose to the workers processes    This is a full config example where we define processor, source and sink conf\nprocessor: handlerPath: ./examples/basic moduleName: handler workers: 2 source: kind: kafka brokers: - localhost:9092 topics: - test offset: latest consumerGroup: my-consumer-group sink: kind: kafka brokers: - localhost:9092 topic: test-out partitioner: hash The handler module Each worker instance, will handle events using a python handler module. A python handler module is a file named (by default) handler.py. The handler.py file must contain at least a function definition called handle_event that receives two parameters:\n context data  So the handler_event signature is:\ndef handle_event(context, data) The context is a persistent object that contains some helpers like a logger. You can also use this object to set some custom attributes at runtime.\nThe data param is a byte array containing the event data as sent from the source to the workers. The return value of handle_event (if any), will be routed back to the configured sink.\nThe handler.py could also define a special function called init_context\ndef init_context(context) The init_context function will be executed only once on worker startup. It can be used to setup some context as for example loading a machine learning model or setup a database connection.\nHandling dependencies You can have a standard python requirements.txt file in the same directory where the handler.py resides, that list the required dependecies. If that file exists, bruco will run pip install -r against it. This behaviur can be disabled eposing an env var:\nexpose BRUCO_DISABLE_PIP=true "},{"uri":"https://ferama.github.io/bruco/tags/","title":"Tags","tags":[],"description":"","content":""}]